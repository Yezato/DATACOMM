# Deploying Ansible
## GOAL
Configure Ansible to manage hosts and run ad hoc Ansible commands.

## OBJECTIVES
- Describe Ansible inventory concepts and manage a static inventory file.
- Describe where Ansible configuration files are located, how Ansible selects them, and edit them to apply changes to default settings.
- Run a single Ansible automation task using an ad hoc command and explain some use cases for ad hoc commands.
## SECTIONS
- Building an Ansible Inventory (and Guided Exercise)
- Managing Ansible Configuration Files (and Guided Exercise)
- Running Ad Hoc Commands (and Guided Exercise)
## LAB
Deploying Ansible

# Building an Ansible Inventory

### Objectives
After completing this section, you should be able to describe Ansible inventory concepts and manage a static inventory file.


### DEFINING THE INVENTORY
An inventory defines a collection of hosts that Ansible will manage. These hosts can also be assigned to groups, which can be managed collectively. Groups can contain child groups, and hosts can be members of multiple groups. The inventory can also set variables that apply to the hosts and groups that it defines.

Host inventories can be defined in two different ways. A static host inventory can be defined by a text file. A dynamic host inventory can be generated by a script or other program as needed, using external information providers.

# Specifying Managed Hosts With A Static Inventory

#### Objectives
A static inventory file is a text file that specifies the managed hosts that Ansible targets. You can write this file using a number of different formats, including INI-style or YAML. The INI-style format is very common and will be used for most examples in this course.

> Note :

> There are multiple static inventory formats supported by Ansible. In this section, we are focusing on the most common one, INI-style format.

In its simplest form, an INI-style static inventory file is a list of host names or IP addresses of managed hosts, each on a single line:
```lua
web1.example.com
web2.example.com
db1.example.com
db2.example.com
192.0.2.42
```
Normally, however, you organize managed hosts into host groups. Host groups allow you to more effectively run Ansible against a collection of systems. In this case, each section starts with a host group name enclosed in square brackets ([]). This is followed by the host name or an IP address for each managed host in the group, each on a single line.

In the following example, the host inventory defines two host groups: webservers and db-servers.
```lua
[webservers]
web1.example.com
web2.example.com
192.0.2.42

[db-servers]
db1.example.com
db2.example.com
```
Hosts can be in multiple groups. In fact, recommended practice is to organize your hosts into multiple groups, possibly organized in different ways depending on the role of the host, its physical location, whether it is in production or not, and so on. This allows you to easily apply Ansible plays to specific hosts.
```lua
[webservers]
web1.example.com
web2.example.com
192.0.2.42

[db-servers]
db1.example.com
db2.example.com

[east-datacenter]
web1.example.com
db1.example.com

[west-datacenter]
web2.example.com
db2.example.com

[production]
web1.example.com
web2.example.com
db1.example.com
db2.example.com

[development]
192.0.2.42
```

> IMPORTANT ( Two host groups always exist ) :

- The all host group contains every host explicitly listed in the inventory.
- The ungrouped host group contains every host explicitly listed in the inventory that is not a member of any other group.

#### Defining Nested Groups
Ansible host inventories can include groups of host groups. This is accomplished by creating a host group name with the : children suffix. The following example creates a new group called north-america, which includes all hosts from the usa and canada groups.
```lua
[usa]
washington1.example.com
washington2.example.com

[canada]
ontario01.example.com
ontario02.example.com

[north-america:children]
canada
usa
```

A group can have both managed hosts and child groups as members. For example, in the previous inventory you could add a [north-america] section that has its own list of managed hosts. That list of hosts would be merged with the additional hosts that the north-america group inherits from its child groups.


#### Simplifying Host Specifications with Ranges
You can specify ranges in the host names or IP addresses to simplify Ansible host inventories. You can specify either numeric or alphabetic ranges. Ranges have the following syntax:
```lua
[START:END]
```
Ranges match all values from START to END, inclusively. Consider the following examples:
- 192.168.[4:7].[0:255] matches all IPv4 addresses in the 192.168.4.0/22 network (192.168.4.0 through 192.168.7.255).
- server[01:20].example.com matches all hosts named server01.example.com through server20.example.com.
- [a:c].dns.example.com matches hosts named a.dns.example.com, b.dns.example.com, and c.dns.example.com.
- 2001:db8::[a:f] matches all IPv6 addresses from 2001:db8::a through 2001:db8::f.

If leading zeros are included in numeric ranges, they are used in the pattern. The second example above does not match server1.example.com but does match server07.example.com. To illustrate this, the following example uses ranges to simplify the [usa] and [canada] group definitions from the earlier example:
```lua
[usa]
washington[1:2].example.com
[canada]
ontario[01:02].example.com
```

#### Verifying the Inventory
When in doubt, use the ansible command to verify a machine's presence in the inventory:

```lua
[user@controlnode ~]$ ansible washington1.example.com --list-hosts
    hosts (1):
        washington1.example.com
[user@controlnode ~]$ ansible washington01.example.com --list-hosts
   [WARNING]: provided hosts list is empty, only localhost is available

    hosts (0):
```
You can run the following command to list all hosts in a group:
```lua
[user@controlnode ~]$ ansible canada --list-hosts
    hosts (2):
        ontario01.example.com
        ontario02.example.com
```
> IMPORTANT :

- If the inventory contains a host and a host group with the same name, the ansible command prints a warning and targets the host. The host group is ignored.
- There are various ways to deal with this situation, the easiest being to ensure that host groups do not use the same names as hosts in the inventory.

#### Overriding the Location of the Inventory
The /etc/ansible/hosts file is considered the system's default static inventory file. However, normal practice is not to use that file but to define a different location for inventory files in your Ansible configuration file. This is covered in the next section.

The ansible and ansible-playbook commands that you use to run Ansible ad hoc commands and playbooks later in the course can also specify the location of an inventory file on the command line with the --inventory PATHNAME or -i PATHNAME option, where PATHNAME is the path to the desired inventory file.


#### Defining Variables in the Inventory
Values for variables used by playbooks can be specified in host inventory files. These variables only apply to specific hosts or host groups. Normally it is better to define these inventory variables in special directories and not directly in the inventory file. This topic is discussed in more depth elsewhere in the course.

# Describing A Dynamic Inventory

#### Describing a Dynamic Inventory
Ansible inventory information can also be dynamically generated, using information provided by external databases. The open source community has written a number of dynamic inventory scripts that are available from the upstream Ansible project. If those scripts do not meet your needs, you can also write your own.

For example, a dynamic inventory program could contact your Red Hat Satellite server or Amazon EC2 account, and use information stored there to construct an Ansible inventory. Because the program does this when you run Ansible, it can populate the inventory with up-to-date information provided by the service as new hosts are added and old hosts are removed.

This topic is discussed in more detail later in the course.

# Lab 2.1: Building an Ansible Inventory
In this exercise, you will create a new static inventory containing hosts and groups.

# OUTCOMES
You should be able to create default and custom static inventories.

1. Modify /etc/ansible/hosts to include servera.lab.example.com as a managed host.

1.1. Add server1.btech.id to the end of the default inventory file, /etc/ ansible/hosts.
```lua
sudo vim /etc/ansible/hosts
server1.btech.id
```
1.2. Continue editing the /etc/ansible/hosts inventory file by adding a [webservers] group to the bottom of the file with serverb.lab.example.com server as a group member.
```lua
sudo vim /etc/ansible/hosts
server1.btech.id

[webservers]
server2.btech.id
```
2. Verify the managed hosts in the /etc/ansible/hosts inventory file.

2.1. Use the ansible all --list-hosts command to list all managed hosts in the default inventory file.
```lua
ansible all --list-hosts
  hosts (2):
    server1.btech.id
    server2.btech.id
```
2.2. Use the ansible ungrouped --list-hosts command to list only managed hosts that do not belong to a group.
```lua
ansible ungrouped --list-hosts
  hosts (1):
    server1.btech.id
```
2.3. Use the ansible webservers --list-hosts command to list only managed hosts that belong to the webservers group.
```lua
ansible webservers --list-hosts
  hosts (1):
    server2.btech.id
```
3. Create a custom static inventory file named inventory in the /home/student/deploy-inventory working directory. Information about your four managed hosts is listed in the following table. You will assign each host to multiple groups for management purposes based on the purpose of the host, the city where it is located, and the deployment environment to which it belongs. In addition, groups for Indonesia cities (Bogor and Bekasi) must be set up as children of the group us so that hosts in the Indonesia can be managed as a group.
Server Inventory Specifications
![image](https://github.com/Yezato/DATACOMM/assets/95903200/76ed83a1-b32f-4977-9955-6c4f7d36c2ce)

3.1. Create the /home/student/deploy-inventory working directory.
```lua
mkdir ~/deploy-inventory
```
3.2. Create an inventory file in the /home/student/deploy-inventory working directory. Use the Server Inventory Specifications table as a guide. Edit the inventory file and add the following content:

# Enter deploy-inventory directory
```lua
cd ~/deploy-inventory
```
# Open text editor
```lua
vim inventory
[webservers]
server[1:4].btech.id

[bogor]
server1.btech.id
server2.btech.id

[bekasi]
server3.btech.id

[jakarta]
server4.btech.id

[development]
server1.btech.id

[testing]
server2.btech.id

[production]
server3.btech.id
server4.btech.id

[id:children]
bogor
bekasi
```
4. Use variations of the ansible host-or-group -i inventory --list-hosts command to verify the managed hosts and groups in the custom /home/student/deploy- inventory/inventory inventory file.

> IMPORTANT

> Your ansible command must include the -i inventory option. This makes ansible use your inventory file in the current working directory instead of the system /etc/ansible/hosts inventory file.

4.1. Use the ansible all -i inventory --list-hosts command to list all managed hosts.
```lua
ansible all -i inventory --list-hosts
  hosts (4):
    server1.btech.id
    server2.btech.id
    server3.btech.id
    server4.btech.id
```
4.2. Use the ansible ungrouped -i inventory --list-hosts command to list all managed hosts listed in the inventory file but are not part of a group. There are no ungrouped managed hosts in this inventory file.
```lua
ansible ungrouped -i inventory --list-hosts
[WARNING]: No hosts matched, nothing to do
  hosts (0):
```
4.3. Use the ansible development -i inventory --list-hosts command to list all managed hosts listed in the development group.
```lua
ansible development -i inventory --list-hosts
  hosts (1):
    server1.btech.id
```
4.4. Use the ansible testing -i inventory --list-hosts command to list all managed hosts listed in the testing group.
```lua
ansible testing -i inventory --list-hosts
  hosts (1):
    server2.btech.id
```
4.5. Use the ansible production -i inventory --list-hosts command to list all managed hosts listed in the production group.
```lua
ansible production -i inventory --list-hosts
  hosts (2):
    server3.btech.id
    server4.btech.id
```
4.6. Use the ansible us -i inventory --list-hosts command to list all managed hosts listed in the us group.
```lua
ansible id -i inventory --list-hosts
  hosts (3):
    server1.btech.id
    server2.btech.id
    server3.btech.id
```
4.7. You are encouraged to experiment with other variations to confirm managed host entries in the custom inventory file.

# Managing Ansible Configuration Files

#### Objectives
After completing this section, you should be able to describe where Ansible configuration files are located, how they are selected by Ansible, and edit them to apply changes to default settings.


#### Configure Ansible
The behavior of an Ansible installation can be customized by modifying settings in the Ansible configuration file. Ansible chooses its configuration file from one of several possible locations on the control node.


#### Using /etc/ansible/ansible.cfg
The ansible package provides a base configuration file located at /etc/ansible/ansible.cfg. This file is used if no other configuration file is found.

#### Using ~/.ansible.cfg
Ansible looks for a .ansible.cfg file in the user's home directory. This configuration is used instead of the /etc/ansible/ansible.cfg if it exists and if there is no ansible.cfg file in the current working directory.

If an ansible.cfg file exists in the directory in which the ansible command is executed, it is used instead of the global file or the user's personal file. This allows administrators to create a directory structure where different environments or projects are stored in separate directories, with each directory containing a configuration file tailored with a unique set of settings.

> Important :

> The recommended practice is to create an ansible.cfg file in a directory from which you run Ansible commands. This directory would also contain any files used by your Ansible project, such as an inventory and a playbook. This is the most common location used for the Ansible configuration file. It is unusual to use a ~/.ansible.cfg or /etc/ansible/ansible.cfg file in practice.


#### Using the ANSIBLE_CONFIG environment variable
You can use different configuration files by placing them in different directories and then executing Ansible commands from the appropriate directory, but this method can be restrictive and hard to manage as the number of configuration files grows. A more flexible option is to define the location of the configuration file with the ANSIBLE_CONFIG environment variable. When this variable is defined, Ansible uses the configuration file that the variable specifies instead of any of the previously mentioned configuration files.
Configuration File Precedence

# Configuration File Precedence
#### Configuration File Precendence
The search order for a configuration file is the reverse of the preceding list. The first file located in the search order is the one that Ansible selects. Ansible only uses configuration settings from the first file that it finds.

Any file specified by the ANSIBLE_CONFIG environment variable overrides all other configuration files. If that variable is not set, the directory in which the ansible command was run is then checked for an ansible.cfg file. If that file is not present, the user's home directory is checked for a .ansible.cfg file. The global /etc/ansible/ansible.cfg file is only used if no other configuration file is found. If the /etc/ansible/ansible.cfg configuration file is not present, Ansible contains defaults which it uses.

Because of the multitude of locations in which Ansible configuration files can be placed, it can be confusing which configuration file is being used by Ansible.

You can run the ansible --version command to clearly identify which version of Ansible is installed, and which configuration file is being used.
```lua
[user@controlnode ~]$ ansible --version
ansible 2.8.0
    config file = /etc/ansible/ansible.cfg
...output omitted...
```
Another way to display the active Ansible configuration file is to use the -v option when executing

Ansible commands on the command line.
```lua
[user@controlnode ~]$ ansible servers --list-hosts -v
Using /etc/ansible/ansible.cfg as config file
...output omitted...
```
Ansible only uses settings from the configuration file with the highest precedence. Even if other files with lower precedence exist, their settings are ignored and not combined with those in the selected configuration file. Therefore, if you choose to create your own configuration file in favor of the global /etc/ansible/ansible.cfg configuration file, you need to duplicate all desired settings from that file to your own user-level configuration file. Settings not defined in the user- level configuration file remain set to the built-in defaults, even if they are set to some other value by the global configuration file.

# Managing Settings In The Configuration File

#### Managing Setting in The Configuration File
The Ansible configuration file consists of several sections, with each section containing settings defined as key-value pairs. Section titles are enclosed in square brackets. For basic operation use the following two sections:

- [defaults] sets defaults for Ansible operation
- [privilege_escalation] configures how Ansible performs privilege escalation on managed hosts
For example, the following is a typical ansible.cfg file:
```lua
[defaults]
inventory = ./inventory
remote_user = user
ask_pass = false
RH294-RHEL8.0-en-1-20190531
29CHAPTER 2 | Deploying Ansible
[privilege_escalation]
become = true
become_method = sudo
become_user = root
become_ask_pass = false
```
The directives in this file are explained in the following table:

Ansible Configuration
![image](https://github.com/Yezato/DATACOMM/assets/95903200/1d0da5f3-77a7-482a-a618-229f9342fb0f)

Image : Basic Ansible Configuration. (@RedHat)

# Configuring Connections

#### Configuring Connections
Ansible needs to know how to communicate with its managed hosts. One of the most common reasons to change the configuration file is to control which methods and users Ansible uses to administer managed hosts. Some of the information needed includes:

- The location of the inventory that lists the managed hosts and host groups
- Which connection protocol to use to communicate with the managed hosts (by default, SSH), and whether or not a nonstandard network port is needed to connect to the server
- Which remote user to use on the managed hosts; this could be root or it could be an unprivileged user
- If the remote user is unprivileged, Ansible needs to know if it should try to escalate privileges to root and how to do it (for example, by using sudo)
- Whether or not to prompt for an SSH password or sudo password to log in or gain privileges

#### Inventory Location
In the [defaults] section, the inventory directive can point directly to a static inventory file, or to a directory containing multiple static inventory files and dynamic inventory scripts.
```lua
[defaults]
inventory = ./inventory
```
#### Connection Settings
By default, Ansible connects to managed hosts using the SSH protocol. The most important parameters that control how Ansible connects to the managed hosts are set in the [defaults] section.

By default, Ansible attempts to connect to the managed host using the same user name as the local user running the Ansible commands. To specify a different remote user, set the remote_user parameter to that user name.

If the local user running Ansible has private SSH keys configured that allow them to authenticate as the remote user on the managed hosts, Ansible automatically logs in.

If that is not the case, you can configure Ansible to prompt the local user for the password used by the remote user by setting the directive ask_pass = true.
```lua
[defaults]
inventory = ./inventory
remote_user = root
ask_pass = true
```
Assuming that you are using a Linux control node and OpenSSH on your managed hosts, if you can log in as the remote user with a password then you can probably set up SSH key-based authentication, which would allow you to set ask_pass = false. The first step is to make sure that the user on the control node has an SSH key pair configured in ~/.ssh. You can run the ssh-keygen command to accomplish this.

For a single existing managed host, you can install your public key on the managed host and use the ssh-copy-id command to populate your local ~/.ssh/known_hosts file with its host key, as follows:
```lua
[user@controlnode ~]$ ssh-copy-id root@web1.example.com
The authenticity of host 'web1.example.com (192.168.122.181)' can't be established.
ECDSA key fingerprint is 70:9c:03:cd:de:ba:2f:11:98:fa:a0:b3:7c:40:86:4b.
Are you sure you want to continue connecting (yes/no)? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter
out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted
now it is to install the new keys
root@web1.example.com's password:

Number of key(s) added: 1

Now try logging into the machine, with: "ssh 'root@web1.example.com'"
and check to make sure that only the key(s) you wanted were added.
```
> Note :

> You can also use an Ansible Playbook to deploy your public key to the remote_user account on all managed hosts using the authorized_key module.

> This course has not covered Ansible Playbooks in detail yet. A play that ensures that your public key is deployed to the managed hosts' root accounts might read as follows:

![image](https://github.com/Yezato/DATACOMM/assets/95903200/5fdc6f85-0b68-4a96-9961-2ecd576e40b3)

- Because the managed host would not have SSH key-based authentication configured yet, you would have to run the playbook using the ansible-playbook command with the --ask-pass option in order for the command to authenticate as the remote user.

#### Escalating Privileges
For security and auditing reasons, Ansible might need to connect to remote hosts as an unprivileged user before escalating privileges to get administrative access as root. This can be set up in the [privilege_escalation] section of the Ansible configuration file.

To enable privilege escalation by default, set the directive become = true in the configuration file. Even if this is set by default, there are various ways to override it when running ad hoc commands or Ansible Playbooks. (For example, there might be times when you want to run a task or play that does not escalate privileges.)

The become_method directive specifies how to escalate privileges. Several options are available, but the default is to use sudo. Likewise, the become_user directive specifies which user to escalate to, but the default is root.

If the become_method mechanism chosen requires the user to enter a password to escalate privileges, you can set the become_ask_pass = true directive in the configuration file.

> Note :

- On Red Hat Enterprise Linux 7, the default configuration of /etc/sudoers grants all users in the wheel group the ability to use sudo to become root after entering their password.
- One way to enable a user (someuser in the following example) to use sudo to become root without a password is to install a file with the appropriate directives into the /etc/sudoers.d directory (owned by root, with octal permissions 0400):

![image](https://github.com/Yezato/DATACOMM/assets/95903200/e860edec-75ba-43f8-968b-e37f9c8ad2d6)

- Think through the security implications of whatever approach you choose for privilege escalation. Different organizations and deployments might have different trade-offs to consider.

The following example ansible.cfg file assumes that you can connect to the managed hosts as someuser using SSH key-based authentication, and that someuser can use sudo to run commands as root without entering a password:

```lua
[defaults]
inventory = ./inventory
remote_user = someuser
ask_pass = false

[privilege_escalation]
become = true
become_method = sudo
become_user = root
become_ask_pass = false
```
#### Non-SSH Connections
The protocol used by Ansible to connect to managed hosts is set by default to smart, which determines the most efficient way to use SSH. This can be set to other values in a number of ways.

For example, there is one exception to the rule that SSH is used by default. If you do not have localhost in your inventory, Ansible sets up an implicit localhost entry to allow you to run ad hoc commands and playbooks that target localhost. This special inventory entry is not included in the all or ungrouped host groups. In addition, instead of using the smart SSH connection type, Ansible connects to it using the special local connection type by default.
```lua
[user@controlnode ~]$ ansible localhost --list-hosts
[WARNING]: provided hosts list is empty, only localhost is available

    hosts (1):
        localhost
```
The local connection type ignores the remote_user setting and runs commands directly on the local system. If privilege escalation is being used, it runs sudo from the user account that ran the Ansible command, not remote_user. This can lead to confusion if the two users have different sudo privileges.

If you want to make sure that you connect to localhost using SSH like other managed hosts, one approach is to list it in your inventory. But, this includes it in the all and ungrouped groups, which you may not want to do.

Another approach is to change the protocol used to connect to localhost. The best way to do this is to set the ansible_connection host variable for localhost. To do this, in the directory from which you run Ansible commands, create a host_vars subdirectory. In that subdirectory, create a file named localhost, containing the line ansible_connection: smart. This ensures that the smart (SSH) connection protocol is used instead of local for localhost.

You can use this the other way around as well. If you have 127.0.0.1 listed in your inventory, by default you will connect to it using smart. You can also create a host_vars/127.0.0.1 file containing the line ansible_connection: local and it will use local instead.

Host variables are covered in more detail later in the course.

> Note :

- You can also use group variables to change the connection type for an entire host group. This can be done by placing files with the same name as the group in a group_vars directory, and ensuring that those files contain settings for the connection variables.
- For example, you might want all your Microsoft Windows managed hosts to use the winrm protocol and port 5986 for connections. To configure this, you could put all of those managed hosts in group windows, and then create a file named group_vars/windows containing the following lines:

 ![image](https://github.com/Yezato/DATACOMM/assets/95903200/6ab3cc74-ddbb-4a67-964c-835bc42b55ce)

# Configuration File Comments

#### Configuration File Coments
There are two comment characters allowed by Ansible configuration files: the hash or number sign (#) and the semicolon (;).

The number sign at the start of a line comments out the entire line. It must not be on the same line with a directive.

The semicolon character comments out everything to the right of it on the line. It can be on the same line as a directive, as long as that directive is to its left.
